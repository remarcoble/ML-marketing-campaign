{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eaa3a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data management\n",
    "import pandas as pd\n",
    "\n",
    "# Math and Stat modules\n",
    "import numpy as np\n",
    "\n",
    "# Data preprocessing and trasformation (ETL)\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, MaxAbsScaler, FunctionTransformer, Binarizer, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "#Imputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "#Supervised Learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, KFold, StratifiedKFold, RepeatedKFold, ShuffleSplit, StratifiedShuffleSplit, learning_curve, validation_curve, cross_validate\n",
    "from sklearn.linear_model import Perceptron, LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, precision_recall_curve, roc_curve\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import VotingClassifier, BaggingClassifier, RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.tree import export_graphviz\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b2770d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"data/marketing_campaign.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf30195f-bbd4-4da3-81a1-3f6521a04bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fb4518",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2303bf",
   "metadata": {},
   "source": [
    "Droppiamo le 3 colonne che non ci servono:\n",
    "- ID\n",
    "- Z_CostContact\n",
    "- Z_Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4353c992",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(columns=['ID', 'Z_CostContact', 'Z_Revenue'], inplace=True)\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7068f83e-604f-4464-bdcb-19d916b9bc5c",
   "metadata": {},
   "source": [
    "Prendo le Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a73bc5-7474-4f52-975c-a371053384cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_label = dataset['Response'].values\n",
    "dataset.drop(columns=['Response'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088b2c2c",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2db64a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.hist(figsize=(22,42), layout=(10, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b617a6-c198-43f9-90a0-dc5cbee5595e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DateTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, startDate = pd.to_datetime(\"2015-01-01\")):\n",
    "        self.startDate = startDate\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_new = pd.to_datetime(X.iloc[:,0])\n",
    "        X_new = pd.DataFrame((self.startDate - X_new).transform(lambda days: days.total_seconds()/(60*60*24*30)))\n",
    "        return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8a16f3-b7d9-4f46-92d5-bfa050a80348",
   "metadata": {},
   "outputs": [],
   "source": [
    "income_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "date_pipeline = Pipeline([\n",
    "    ('transformer', DateTransformer()),\n",
    "    ('scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bfb48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_features = ['Year_Birth', 'NumWebVisitsMonth', 'NumWebPurchases', 'NumCatalogPurchases', 'NumDealsPurchases']\n",
    "standard_features = ['Recency', 'MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds', 'NumStorePurchases']\n",
    "\n",
    "data_preprocessing = ColumnTransformer([\n",
    "    ('robust', StandardScaler(), standard_features),\n",
    "    ('cat', OneHotEncoder(), ['Education', 'Marital_Status']),\n",
    "    ('standard', RobustScaler(), robust_features),\n",
    "    ('income', income_pipeline, ['Income']),\n",
    "    ('dateSubscription', date_pipeline, [\"Dt_Customer\"])\n",
    "],\n",
    "    remainder = 'passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a31570",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix = data_preprocessing.fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cc95c6-8e09-4cfc-8862-58ad1df1f82e",
   "metadata": {},
   "source": [
    "Ricreo nomi colonne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00a34bd-e9b0-42a8-ad85-3234c0ecb300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns_name = robust_features\n",
    "# for c in ['Education', 'Marital_Status']:\n",
    "#     cat_inc_name = [c+f\"_cat{i}\" for i in range(1,len(dataset[c].unique()))]\n",
    "#     columns_name.extend(cat_inc_name)\n",
    "# columns_name.extend(standard_features)\n",
    "# columns_name.extend(dataset.columns.difference(columns_name))\n",
    "# columns_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5542ff0d",
   "metadata": {},
   "source": [
    "## Test and Training set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1127e79",
   "metadata": {},
   "source": [
    "Prendo le label e elimino quella colonna dal dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3127702-0fae-4cd5-b161-22d6e2c8b57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(feature_matrix, dataset_label, test_size = 0.3, random_state = 42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a57b5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron = Perceptron()\n",
    "perceptron.fit(X_train, y_train) # apprendo su training\n",
    "predicted_test = perceptron.predict(X_test) # predico sul test\n",
    "np.sum(predicted_test == y_test)/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9869052b",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Perceptron()\n",
    "p_score = cross_val_score(p, X_train, y_train, cv = 5).mean()\n",
    "p_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800ca6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ci dice per ogni record che prediction ha ricevuto quando faceva parte del validation set\n",
    "#cross_val_predict(perceptron, X_train, y_train, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8e5be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "kf_score = cross_val_score(p, X_train, y_train, cv = kf).mean()\n",
    "kf_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e3f8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "rkf = RepeatedKFold(n_splits=5, n_repeats=4)\n",
    "rkf_score = cross_val_score(p, X_train, y_train, cv = rkf).mean()\n",
    "rkf_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634fe8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spf = ShuffleSplit(n_splits = 10, test_size = 0.25)\n",
    "spf_score = cross_val_score(p, X_train, y_train, cv = spf, n_jobs=-1).mean()\n",
    "spf_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5beed2e",
   "metadata": {},
   "source": [
    "Abbiamo un dataset molto sbilanciato. Provo con StratifiedKFold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043411e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(dataset_label).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e95c98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=10)\n",
    "skf_score = cross_val_score(p, X_train, y_train, cv = skf, n_jobs=-1).mean()\n",
    "skf_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed1d21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssf = StratifiedShuffleSplit(n_splits=10)\n",
    "ssf_score = cross_val_score(p, X_train, y_train, cv = ssf, n_jobs=-1).mean()\n",
    "ssf_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea6708b",
   "metadata": {},
   "source": [
    "Provo a confrontare con dei DummyClassifier il Perceptron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c61ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_dum_cls = DummyClassifier(strategy='most_frequent')\n",
    "uni_dum_cls = DummyClassifier(strategy='uniform')\n",
    "st_dum_cls = DummyClassifier(strategy='stratified')\n",
    "\n",
    "mf_score = cross_val_score(mf_dum_cls, X_train, y_train, cv=10, scoring='accuracy').mean()\n",
    "uni_score = cross_val_score(uni_dum_cls, X_train, y_train, cv=10, scoring='accuracy').mean()\n",
    "st_score = cross_val_score(st_dum_cls, X_train, y_train, cv=10, scoring='accuracy').mean()\n",
    "\n",
    "print(\"---------- Dummy Classifiers ----------\\n\")\n",
    "print(\"Most frequent score:\", mf_score)\n",
    "print(\"Uniform score:\", uni_score)\n",
    "print(\"Stratified score:\", st_score)\n",
    "print(\"\\n---------- Serious Classifiers ----------\\n\")\n",
    "print(\"Perceptron score:\", p_score)\n",
    "print(\"KFold score:\", kf_score)\n",
    "print(\"Repeated KFold score:\", rkf_score)\n",
    "print(\"Shuffle Split score:\", spf_score)\n",
    "print(\"Stratified KFold score:\", skf_score)\n",
    "print(\"Stratified Shuffle Split score:\", ssf_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85241114",
   "metadata": {},
   "source": [
    "Analizziamo le performance con matrice di confusione, precison, recall e f1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9237bf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predicted = cross_val_predict(p, X_train, y_train, cv = 10)\n",
    "cm = confusion_matrix(y_train, y_train_predicted)\n",
    "cm_display = ConfusionMatrixDisplay(cm).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a13893",
   "metadata": {},
   "source": [
    "Vediamo le performance del perceptron confrontate ai dummy classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9d5184",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_mf = cross_val_predict(mf_dum_cls, X_train, y_train, cv = 10)\n",
    "y_train_un = cross_val_predict(uni_dum_cls, X_train, y_train, cv = 10)\n",
    "y_train_st = cross_val_predict(st_dum_cls, X_train, y_train, cv = 10)\n",
    "\n",
    "print(\"------------ Perceptron ------------\", \"\\nPrecision:\", precision_score(y_train, y_train_predicted), \"\\nRecall:\", recall_score(y_train, y_train_predicted), \"\\nf1:\", f1_score(y_train, y_train_predicted))\n",
    "print(\"\\n------------ Most frequent ------------\", \"\\nPrecision:\", precision_score(y_train, y_train_mf), \"\\nRecall:\", recall_score(y_train, y_train_mf), \"\\nf1:\", f1_score(y_train, y_train_mf))\n",
    "print(\"\\n------------ Uniform ------------\", \"\\nPrecision:\", precision_score(y_train, y_train_un), \"\\nRecall:\", recall_score(y_train, y_train_un), \"\\nf1:\", f1_score(y_train, y_train_un))\n",
    "print(\"\\n------------ Stratified ------------\", \"\\nPrecision:\", precision_score(y_train, y_train_st), \"\\nRecall:\", recall_score(y_train, y_train_st), \"\\nf1:\", f1_score(y_train, y_train_st))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26ef0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metti max_iter=100 e guarda link su preprocessing\n",
    "logit_cls = LogisticRegression(max_iter=100)\n",
    "y_scores = cross_val_predict(logit_cls, X_train, y_train, cv = 5, method='decision_function')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e220dc6b-8a86-4e87-b789-212b413e1285",
   "metadata": {},
   "outputs": [],
   "source": [
    "prec, recall, soglia = precision_recall_curve(y_train, y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b184f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_prc = plt.figure(figsize=(16,9))\n",
    "ax = fig_prc.add_subplot()\n",
    "ax.plot(soglia, prec[:-1], 'r', label = 'precision')\n",
    "ax.plot(soglia, recall[:-1], 'b', label = 'recall')\n",
    "ax.legend(fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810d6f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_prf = plt.figure(figsize=(16,12))\n",
    "ax = fig_prf.add_subplot()\n",
    "ax.plot(recall[:-1], prec[:-1], 'r', label = 'precision', lw = 4)\n",
    "ax.set_xlabel(\"Recall\")\n",
    "ax.set_ylabel(\"Precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574fbcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "soglia_prec_90 = soglia[np.argmax(prec >= 0.5)]\n",
    "y_predicted_score = y_scores >= soglia_prec_90\n",
    "precision_score(y_train, y_predicted_score), recall_score(y_train, y_predicted_score), f1_score(y_train, y_predicted_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a91d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, recall, soglia = roc_curve(y_train, y_scores)\n",
    "\n",
    "fig_roc = plt.figure(figsize=(16,12))\n",
    "ax = fig_roc.add_subplot()\n",
    "ax.plot(fpr, recall, 'r', label = 'recall', lw = 7)\n",
    "ax.set_xlabel(\"FPR\")\n",
    "ax.set_ylabel(\"Recall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270faed8",
   "metadata": {},
   "source": [
    "Learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949b4487",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes, train_scores, test_scores = learning_curve(logit_cls,\n",
    "                                                       X=feature_matrix,\n",
    "                                                       y=dataset_label,\n",
    "                                                       train_sizes= [0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "                                                       cv = 10,\n",
    "                                                       n_jobs = -1,\n",
    "                                                       shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f877ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "fig=plt.figure(figsize=(12,7))\n",
    "ax = fig.add_subplot()\n",
    "ax.plot(train_sizes, train_scores[:,0],\n",
    "         color='blue', marker='o',\n",
    "         markersize=5, label='Training accuracy - fold 1')\n",
    "\n",
    "ax.plot(train_sizes, train_mean,\n",
    "         color='blue', marker='+',\n",
    "         markersize=5, label='Training accuracy')\n",
    "\n",
    "ax.fill_between(train_sizes,\n",
    "                 train_mean + train_std,\n",
    "                 train_mean - train_std,\n",
    "                 alpha=0.15, color='blue')\n",
    "\n",
    "ax.plot(train_sizes, test_scores[:,0],\n",
    "         color='green', linestyle='--',\n",
    "         marker='s', markersize=5,\n",
    "         label='Validation accuracy - fold 1')\n",
    "\n",
    "ax.plot(train_sizes, test_mean,\n",
    "         color='green', linestyle='--',\n",
    "         marker='d', markersize=5,\n",
    "         label='Validation accuracy')\n",
    "\n",
    "ax.fill_between(train_sizes,\n",
    "                 test_mean + test_std,\n",
    "                 test_mean - test_std,\n",
    "                 alpha=0.15, color='green')\n",
    "\n",
    "ax.grid()\n",
    "ax.set_xlabel('Dimensione del training set')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.legend(loc='lower right')\n",
    "ax.set_ylim([0.6, 1.03])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35a7782",
   "metadata": {},
   "outputs": [],
   "source": [
    "range_C = [0.001,0.01,0.1,1,10,100]\n",
    "train_scores, test_scores = validation_curve(logit_cls, X=feature_matrix, y=dataset_label, param_range=range_C, param_name='C',cv=10, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00718053",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "fig=plt.figure(figsize=(12,7))\n",
    "ax = fig.add_subplot()\n",
    "ax.plot(range_C, train_mean,\n",
    "         color='blue', marker='o',\n",
    "         markersize=5, label='Training accuracy')\n",
    "\n",
    "ax.fill_between(range_C,\n",
    "                 train_mean + train_std,\n",
    "                 train_mean - train_std,\n",
    "                 alpha=0.15, color='blue')\n",
    "\n",
    "ax.plot(range_C, test_mean,\n",
    "         color='green', linestyle='--',\n",
    "         marker='s', markersize=5,\n",
    "         label='Validation accuracy')\n",
    "\n",
    "ax.fill_between(range_C,\n",
    "                 test_mean + test_std,\n",
    "                 test_mean - test_std,\n",
    "                 alpha=0.15, color='green')\n",
    "\n",
    "ax.grid()\n",
    "ax.set_xlabel('Parametro C')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.legend(loc='lower right')\n",
    "ax.set_ylim([0.8, 0.9])\n",
    "ax.set_xlim([0., 1.03])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c450fa60",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845bebf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cs = [0.01, 0.1, 1, 10, 100]# definire un insieme di valori di C tenendo in considerazione le precedenti osservazioni sul suo effetto \n",
    "fig = plt.figure(figsize=(18,3.2))\n",
    "for i, c in enumerate(Cs):\n",
    "    print('Training SVM per C =', c, i)\n",
    "    svm_cls = LinearSVC(C = c, max_iter=50000)\n",
    "    train_sizes, train_scores, test_scores = learning_curve(svm_cls, X = feature_matrix, y = dataset_label, train_sizes=np.linspace(0.1,1,10), cv = 5, n_jobs=-1, shuffle = True)\n",
    "    \n",
    "\n",
    "    print('Training per {} finito'.format(c))\n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    train_std = np.std(train_scores, axis=1)\n",
    "    test_mean = np.mean(test_scores, axis=1)\n",
    "    test_std = np.std(test_scores, axis=1)\n",
    "    ax = fig.add_subplot(150+(i+1))\n",
    "    ax.plot(train_sizes, train_mean,\n",
    "         color='blue', marker='o',\n",
    "         markersize=5, label='Training accuracy')\n",
    "    ax.fill_between(train_sizes,\n",
    "                 train_mean + train_std,\n",
    "                 train_mean - train_std,\n",
    "                 alpha=0.15, color='blue')\n",
    "    ax.plot(train_sizes, test_mean,\n",
    "         color='green', linestyle='--',\n",
    "         marker='s', markersize=5,\n",
    "         label='Validation accuracy')\n",
    "    ax.fill_between(train_sizes,\n",
    "                 test_mean + test_std,\n",
    "                 test_mean - test_std,\n",
    "                 alpha=0.15, color='green')\n",
    "    ax.grid()\n",
    "    ax.set_ylim((0.8,1))\n",
    "    ax.set_xlabel('Dimensione del training set')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803d8e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma1, gamma2 = 0.1, 2\n",
    "C1, C2 = 0.01, 5\n",
    "hyperparams = (gamma1, C1), (gamma1, C2), (gamma2, C1), (gamma2, C2)\n",
    "\n",
    "train_sizes, train_means, test_means, test_stds, train_stds = [],[],[],[],[]\n",
    "for gamma, C in hyperparams:\n",
    "    rbf_kernel_svm_clf = SVC(kernel=\"rbf\", gamma = gamma, C = C)\n",
    "    train_size, train_scores, test_scores = learning_curve(rbf_kernel_svm_clf,\n",
    "                                                       X=feature_matrix,\n",
    "                                                       y=dataset_label,\n",
    "                                                       train_sizes=np.linspace(0.1,1.0,10),\n",
    "                                                       cv=5,\n",
    "                                                       n_jobs=-1)\n",
    "    print('fatto {},{}'.format(gamma,C))\n",
    "    train_means.append(np.mean(train_scores, axis=1))\n",
    "    train_stds.append(np.std(train_scores, axis=1))\n",
    "    test_means.append(np.mean(test_scores, axis=1))\n",
    "    test_stds.append(np.std(test_scores, axis=1))\n",
    "    train_sizes.append(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3c3e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig= plt.figure(figsize=(12, 8))\n",
    "for i in range(4):\n",
    "    ax = fig.add_subplot(221+i)\n",
    "    ax.plot(train_sizes[i], train_means[i],\n",
    "         color='blue', marker='o',\n",
    "         markersize=5, label='Training accuracy')\n",
    "    ax.fill_between(train_sizes[i],\n",
    "                 train_means[i] + train_stds[i],\n",
    "                 train_means[i] - train_stds[i],\n",
    "                 alpha=0.15, color='blue')\n",
    "    ax.plot(train_sizes[i], test_means[i],\n",
    "         color='green', linestyle='--',\n",
    "         marker='s', markersize=5,\n",
    "         label='Validation accuracy')\n",
    "    ax.fill_between(train_sizes[i],\n",
    "                 test_means[i] + test_stds[i],\n",
    "                 test_means[i] - test_stds[i],\n",
    "                 alpha=0.15, color='green')\n",
    "    ax.grid()\n",
    "    ax.set_ylim((0.8,1))\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.legend(loc='lower right')\n",
    "    ax.set_title(r\"$\\gamma={}, C={}$\".format(*hyperparams[i]), fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670c5af7",
   "metadata": {},
   "source": [
    "## Alberi di decisione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a1ac05",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_leaf = [5, 10, 100, 200, 350]\n",
    "\n",
    "train_sizes, train_means, test_means, test_stds, train_stds = [],[],[],[],[]\n",
    "for mlf in min_leaf:\n",
    "    dt_mlf = DecisionTreeClassifier(min_samples_leaf=mlf, random_state=42, max_depth=15)\n",
    "    train_size, train_scores, test_scores = learning_curve(dt_mlf,\n",
    "                                                       X=feature_matrix,\n",
    "                                                       y=dataset_label,\n",
    "                                                       train_sizes=np.linspace(0.1,1.0,10),\n",
    "                                                       cv=10,\n",
    "                                                       n_jobs=-1)\n",
    "    print('fatto {}'.format(mlf))\n",
    "    train_means.append(np.mean(train_scores, axis=1))\n",
    "    train_stds.append(np.std(train_scores, axis=1))\n",
    "    test_means.append(np.mean(test_scores, axis=1))\n",
    "    test_stds.append(np.std(test_scores, axis=1))\n",
    "    train_sizes.append(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a529fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig= plt.figure(figsize=(12, 8))\n",
    "for i in range(5):\n",
    "    ax = fig.add_subplot(231+i)\n",
    "    ax.plot(train_sizes[i], train_means[i],\n",
    "         color='blue', marker='o',\n",
    "         markersize=5, label='Training accuracy')\n",
    "    ax.fill_between(train_sizes[i],\n",
    "                 train_means[i] + train_stds[i],\n",
    "                 train_means[i] - train_stds[i],\n",
    "                 alpha=0.15, color='blue')\n",
    "    ax.plot(train_sizes[i], test_means[i],\n",
    "         color='green', linestyle='--',\n",
    "         marker='s', markersize=5,\n",
    "         label='Validation accuracy')\n",
    "    ax.fill_between(train_sizes[i],\n",
    "                 test_means[i] + test_stds[i],\n",
    "                 test_means[i] - test_stds[i],\n",
    "                 alpha=0.15, color='green')\n",
    "    ax.grid()\n",
    "    ax.set_ylim((0.8,1))\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.legend(loc='lower right')\n",
    "    ax.set_title(r\"min_sam_leaf:{}\".format(min_leaf[i]), fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0604f7",
   "metadata": {},
   "source": [
    "## Ensemble methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b8d72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_ensemble_performance(ax, X, y, scores, scoring):\n",
    "    data_score = []\n",
    "    labels = []\n",
    "    for clf in scores['estimator'][0].estimators_:\n",
    "        scores_clf = cross_validate(clf, X, y,\n",
    "                        cv = StratifiedShuffleSplit(n_splits=20, test_size=0.2, random_state=42),\n",
    "                        return_train_score= True,\n",
    "                        scoring = scoring,\n",
    "                        n_jobs=-1)\n",
    "        data_score.extend([scores_clf[t+s] for s in scoring for t in ['train_','test_']])\n",
    "        labels.extend([clf.__class__.__name__+'_'+t+s for s in scoring for t in ['train_','test_']])\n",
    "    data_score.extend([scores[t+s] for s in scoring for t in ['train_','test_']])\n",
    "    labels.extend(['Voting_'+t+s for s in scoring for t in ['train_','test_']])\n",
    "    sns.boxplot(ax = ax,\n",
    "                data = data_score,\n",
    "                whis = [5, 95],\n",
    "                palette = \"vlag\",\n",
    "                orient = 'h'\n",
    "               )\n",
    "    ax.set(yticklabels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f59e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_clf = LogisticRegression(random_state=42)\n",
    "svm_clf = SVC(random_state=42)\n",
    "per_clf = Perceptron(random_state=42)\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('pc', per_clf), ('svc', svm_clf)],\n",
    "    voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4838a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_validate(voting_clf, feature_matrix, dataset_label,\n",
    "                        cv = StratifiedShuffleSplit(n_splits=20, test_size=0.2, random_state=42),\n",
    "                        return_estimator = True,\n",
    "                        return_train_score= True,\n",
    "                        scoring = ['recall','accuracy','f1'],\n",
    "                        n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a141496",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "ax = fig.add_subplot()\n",
    "visualize_ensemble_performance(ax, feature_matrix, dataset_label, scores, ['recall','accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dce32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_clf = BaggingClassifier(DecisionTreeClassifier(max_depth=3), n_estimators=500, max_samples=200, bootstrap=True, n_jobs=-1)\n",
    "dt_clf = DecisionTreeClassifier(min_samples_leaf=100, random_state=42, max_depth=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2746706",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes, train_means, test_means, test_stds, train_stds = [],[],[],[],[]\n",
    "for clf in [bag_clf, dt_clf]:\n",
    "    train_size, train_scores, test_scores = learning_curve(clf,\n",
    "                                                       X=feature_matrix,\n",
    "                                                       y=dataset_label,\n",
    "                                                       train_sizes=np.linspace(0.1,1.0,10),\n",
    "                                                       cv=StratifiedShuffleSplit(n_splits=10, test_size=0.2, random_state=42),\n",
    "                                                       n_jobs=-1)\n",
    "    print('fatto {}'.format(clf))\n",
    "    train_means.append(np.mean(train_scores, axis=1))\n",
    "    train_stds.append(np.std(train_scores, axis=1))\n",
    "    test_means.append(np.mean(test_scores, axis=1))\n",
    "    test_stds.append(np.std(test_scores, axis=1))\n",
    "    train_sizes.append(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cbdf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig= plt.figure(figsize=(12, 8))\n",
    "for i in range(2):\n",
    "    ax = fig.add_subplot(121+i)\n",
    "    ax.plot(train_sizes[i], train_means[i],\n",
    "         color='blue', marker='o',\n",
    "         markersize=5, label='Training accuracy')\n",
    "    ax.fill_between(train_sizes[i],\n",
    "                 train_means[i] + train_stds[i],\n",
    "                 train_means[i] - train_stds[i],\n",
    "                 alpha=0.15, color='blue')\n",
    "    ax.plot(train_sizes[i], test_means[i],\n",
    "         color='green', linestyle='--',\n",
    "         marker='s', markersize=5,\n",
    "         label='Validation accuracy')\n",
    "    ax.fill_between(train_sizes[i],\n",
    "                 test_means[i] + test_stds[i],\n",
    "                 test_means[i] - test_stds[i],\n",
    "                 alpha=0.15, color='green')\n",
    "    ax.grid()\n",
    "    ax.set_ylim((0.8,1))\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e3e9e4-f49b-49b9-9df1-8b25e8705ddc",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb1ea85-863f-49f0-a78b-a6733a3808b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(feature_matrix, dataset_label, test_size=0.2, stratify=dataset_label)\n",
    "len(y_train[y_train == 1])/len(y_train), len(y_test[y_test == 1])/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe61a7a8-8bd1-4a9b-bd7d-08033b2837ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnf_clf = RandomForestClassifier(n_estimators=250, max_leaf_nodes=64, n_jobs=-1, max_features=10)\n",
    "et_clf = ExtraTreesClassifier(n_estimators=250, max_leaf_nodes=64, n_jobs=-1, max_features=10)\n",
    "scores_rnf = cross_val_score(rnf_clf, X_train, y_train, cv=5, scoring='f1', n_jobs=-1)\n",
    "scores_et = cross_val_score(et_clf, X_train, y_train, cv=5, scoring='f1',n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b82dcb-5782-46c7-ac1a-f3c5cbe586ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,4))\n",
    "ax = fig.add_subplot()\n",
    "sns.boxplot(ax = ax,\n",
    "            data = [scores_rnf, scores_et],\n",
    "            palette = 'vlag',\n",
    "            orient = 'h'\n",
    "           )\n",
    "ax.set(yticklabels=['RF','ET'], xlabel=\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a280f8-0d71-4780-8d24-a5d2e93d2fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_clf = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=6),\n",
    "    n_estimators=250,\n",
    "    algorithm='SAMME.R',\n",
    "    learning_rate=0.5\n",
    ")\n",
    "scores_ada = cross_val_score(ada_clf, X_train, y_train, cv=5, scoring='f1', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928fa588-2c11-4bae-91e5-07a5d5539422",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,4))\n",
    "ax = fig.add_subplot()\n",
    "sns.boxplot(ax = ax,\n",
    "            data = [scores_rnf, scores_et, scores_ada],\n",
    "            palette = 'vlag',\n",
    "            orient = 'h'\n",
    "           )\n",
    "ax.set(yticklabels=['RF','ET','ADA'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
